
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Near Real-time Processing Over Hadoop and HBase - Engineering Health</title>
  <meta name="author" content="Cerner">

  
  <meta name="description" content="">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://engineering.cerner.com/2013/02/near-real-time-processing-over-hadoop-and-hbase">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/bootstrap/bootstrap.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/bootstrap/responsive.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/syntax/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/site/site.css" media="screen, projection" rel="stylesheet" type="text/css">

  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <script src="/javascripts/libs/bootstrap.min.js"></script>

  <link href="/atom.xml" rel="alternate" title="Engineering Health" type="application/atom+xml">
  <script src="/javascripts/search.min.js" type="text/javascript" charset="utf-8"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37701128-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body  class="top-navbar  ">
  



<header id="banner" role="banner" class="container-fluid banner-kc-background">

  <div class="image">

    
      <img src="/images/KC.png" alt="Kansas City" />
    

    <div id="header1">Engineering Health<br/><span class="header2">A <b>Cerner</b> Blog</span></div>

  </div>
  <nav class="navbar navbar-inverse" role="navigation">
  <div class="container">
    <div class="navbar-inner">
      <a class="brand" href="#">Engineering Health</a>
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>
      <div class="nav-collapse collapse">
        <ul class="nav">
          <li >
            <a href="/">Blog</a>
          </li>
          <li >
            <a href="/culture">Culture</a>
          </li>
          <li >
            <a href="/tech_talks">Tech Talks</a>
          </li>
          <li >
            <a href="/open_source">Open Source</a>
          </li>
          <li >
            <a href="/blog/archives">Archives</a>
          </li>
        </ul>
        <div id="search" class="pull-right">
          <form action="/search" method="get" class="navbar-search">
            <input type="text" id="search-query" name="q" class="search-query" placeholder="Search" autocomplete="off">
            <img src="/images/MagnifyingGlass.png" alt="Search" width="16" height="16" />
          </form>
        </div>
      </div>
    </div>
  </div>
</nav>

</header>


  <div class="container-fluid post-container">
    <div class="row-fluid">
      <section class="span12" id="search-results" style="display: none;">
  <h2>Search results</h2>
  <div class="entries">
  </div>
</section>
    </div>
    <div class="row-fluid">
      
<article id="main" class="hentry span8" role="article">

  <section class="post">
    
  <header class="entry-header">
    
      <h1 class="entry-title">Near Real-time Processing Over Hadoop and HBase</h1>
    
    
      <div class="entry-meta meta">
        








  


<time datetime="2013-02-27T00:00:00-06:00" pubdate data-updated="true">Feb 27<span>th</span>, 2013</time> | 
  


  <span class="byline author vcard">
    <span class="fn">Ryan Brush</span>
  </span>


        
      </div>
    
  </header>


<div class="entry-content"><h2>From MapReduce to realtime</h2>

<p>This post covers much of the <a href="http://na.apachecon.com/schedule/presentation/161/">Near-Realtime Processing Over HBase</a> talk I’m giving at <a href="http://na.apachecon.com/">ApacheCon NA 2013</a> in blog form. It also draws from the <a href="http://strataconf.com/stratany2012/public/schedule/detail/25387">Hadoop, HBase, and Healthcare</a> talk from StrataConf/Hadoop World 2012.</p>

<p>The first significant use of Hadoop at Cerner came in building search indexes for patient charts. While creation of simple search indexes is almost commoditized, we wanted a better experience based on clinical semantics. For instance, if a user searches for &ldquo;heart disease&rdquo; and a patient has &ldquo;myocardial infarction&rdquo; documented, that document should be highly ranked in the results.</p>

<p>Analyzing and semantically annotating can be computationally expensive, especially when building indexes that could grow into the billions. Algorithms in this space may be discussed in a future blog post, but for now we focus on creation of an infrastructure up to the computational demands. For this, Hadoop is a great fit. A search index is logically a function of a set of input data, and MapReduce allows us to apply such functions in parallel across an arbitrarily large data set.</p>

<p><img class="center" src="/assets/2013-02-27-near-real-time-processing-over-hadoop-and-hbase/chart-search-screen.png" title="Chart Search" ></p>

<h4>A trend towards competing needs</h4>

<p>The above pattern is powerful but creates a nice problem to have: people want the output of the processing &mdash; in this case, updates to search indexes &mdash; faster. Since we cannot run a MapReduce job over our entire data set every millisecond, we encounter competing needs; the need to <em>process all data holistically</em> conflicts with the need to <em>quickly apply incremental updates</em> to that processing.</p>

<p>This difference may seem simple, but has deep implications.  For instance:</p>

<ul>
<li><p>With MapReduce we can move our computation to the data, but fast updates require moving data to computation.</p></li>
<li><p>MapReduce jobs produce output as a pure function of the input; realtime processing needs to handle outdated state. For instance, we build a phone book and a name changes from Smith to Jones, realtime processing must remove the outdated entry, whereas MapReduce simply rebuilds the whole phone book.</p></li>
<li><p>MapReduce jobs often assume a static set of complete data, whereas realtime processing may see partial data or new data introduce in an unexpected order.</p></li>
</ul>


<p>And despite these differences, our processing output must be the identical; we need to apply the same logic across very different processing models.</p>

<h2>Realtime and batch layers</h2>

<p>These significant differences mean different processing infrastructures. Nathan Marz described this well in his <a href="http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html">How to Beat the CAP Theorem</a> post. The result is a system that uses complementary technologies: stream-based processing with <a href="http://storm-project.net/" title="">Storm</a> and batch processing with Hadoop.</p>

<p>Interestingly, <a href="http://hbase.apache.org/" title="">HBase</a> sits at a juncture between realtime and batch processing models. It offers aspects of batch processing; computation can be moved to the data via direct MapReduce support. It also supports realtime patterns with random access and fast</p>

<p><img class="center" src="/assets/2013-02-27-near-real-time-processing-over-hadoop-and-hbase/realtime-layer-batch-layer.png" title="Realtime and Batch Layers" ></p>

<p>reads and writes. So our realtime and batch layers can be viewed like this:</p>

<ol>
<li>Data entering the system is persisted in HBase.</li>
<li>MapReduce jobs are used to create artifacts useful to consumers at scale.</li>
<li>Incremental updates are handled in realtime by processing updates to HBase in a Storm cluster, and are applied to the artifacts produced by MapReduce jobs.</li>
</ol>


<h2>Processing HBase updates in realtime</h2>

<p>So new data lands in HBase but how does Storm know to process it? There is precedent here. Google’s <a href="http://research.google.com/pubs/pub36726.html">Percolator paper</a> describes a technique for doing so over BigTable: it writes a notification entry to a column family whenever a row changes. Processing components scan for notifications and process them as they enter the system.</p>

<p>This is the general approach we have taken to initiate processing in Storm. Google’s Percolator strategy does not translate directly to HBase. Differences in the way regions are managed versus BigTable tables made using a different column family impractical. So we use a separate &ldquo;notification&rdquo; table to track changes to the original.  Updates to HBase go through an API that writes notification entries as well as the data itself. We then wrote a specialized Storm spout that scans the notification table to initiate processing of updates.</p>

<p>The result is processing infrastructure like this, with Storm Spouts and bolts complementing conventional MapReduce processing:</p>

<p><img class="center" src="/assets/2013-02-27-near-real-time-processing-over-hadoop-and-hbase/processing-diagram.png" title="Processing Diagram" ></p>

<p>The processed data model may be another set of HBase tables, a relational database, or some other data store. Its design should be centered on the needs of the applications and services, letting the processing infrastructure build data for those needs. It is important to note that MapReduce output should be done with a bulk load operation in order to avoid saturating the processed data store with individual updates.</p>

<p>This basic model turns out to be robust. Volume spikes from source systems can be spread throughout the HBase cluster. There are a couple key steps for success here:</p>

<ul>
<li><p>Regular major compactions on the notification HBase tables are essential. Without major compactions, completed notifications will pile up and performance of the system will gradually degrade.</p></li>
<li><p>The notification tables themselves may be small in size, but should be aggressively split across the cluster. This spreads load to handle volume spikes and improve concurrency.</p></li>
</ul>


<p>Also note that MapReduce is still an important part of the system. It’s simply a better tool for batch operations like bringing a new data set online or re-processing an existing data set with new logic.</p>

<h2>Measure Everything</h2>

<p>There are a number of moving parts in this system, and good measurements are the best way to ensure it’s working well. For example, in development we found our HBase Region Servers would encounter frequent but short-lived process queues during heavy load. This didn’t look like an issue in HBase, but when we measured the performance of the calling process there was a noticeable degradation. The point is, instrumentation built into Hadoop and HBase are great but not sufficient. Measuring the observed performance at all layers is important to create an optimal system.</p>

<p>There are many good technologies for doing so. We generally use the <a href="https://github.com/codahale/metrics">Metrics API</a> by Coda Hale. Here is an example of HBase client throughput using an instrumented implementation of HTableInterface. The data is collected by the Metrics API and displayed with <a href="http://graphite.wikidot.com/">Graphite</a>:</p>

<p><img class="center" src="/assets/2013-02-27-near-real-time-processing-over-hadoop-and-hbase/measure-everything.png" title="Measure Everything" ></p>

<h2>Different models, same logic</h2>

<p>The same logic needs to be applied to both batch and stream processing despite the necessary differences in infrastructure. This is a challenge since the models speak very different languages: InputFormats describe an immutable and complete set of data, whereas event streams expose incremental changes without context.</p>

<p>It turns out the function is the only real commonality between them; simply taking a subset of input and returning useful output. So, our strategy is this:</p>

<p><em>Build all logic as a set of simple functions, then compose and coordinate those functions with higher-level processing libraries.</em></p>

<p>We use Storm to compose our realtime processing and Apache Crunch to compose our MapReduce jobs. Here are some lessons we have learned to apply this strategy effectively:</p>

<h4>Minimize intermediate state</h4>

<p>Persisting intermediate state can be expensive and creates complex relationships between moving parts. This is particularly true if a MapReduce job creates intermediate state used by realtime processing or vice versa. Instead, keep processing pipelines independent whenever possible and combine the results at the end.</p>

<h4>Isolate processing models</h4>

<p>Our MapReduce jobs are typically run on separate infrastructure than realtime processing to ensure expensive jobs do not saturate time-critical processing.</p>

<h4>Be aware of the semantic differences in the processing models</h4>

<p>A &ldquo;join&rdquo; in a MapReduce job sees all data, whereas a &ldquo;join&rdquo; in stream processing gets incremental subsets. If a function needs the full context to execute, that context must be externally loaded in the realtime processing system. In our case, external state is loaded from HBase and cached, but projects like <a href="http://engineering.twitter.com/2012/08/trident-high-level-abstraction-for.html">Trident</a> are now providing some aggregation facilities over storm as well.</p>

<h2>The path forward</h2>

<p>The patterns here have been successful but require significant scaffolding and infrastructure to bring together. Near-realtime processing demands over big data are bound to increase, which means there is an opportunity here; higher level abstractions should emerge. Similar to how tools like Crunch and Hive offer abstractions over MapReduce, it’s likely that similar primitives can express the patterns described here.</p>

<p>How these higher abstractions emerge remains to be seen, but there is one thing I’m sure of: it’s going to be fun.</p>

<h2>Acknowledgments</h2>

<p>I’d like to acknowledge key contributors to building this and related systems: Jason Bray, Ben Brown, Robert Farr, Preston Koprivica, Swarnim Kulkarni, Kyle McGovern, Andrew Olson, Mike Richards, Micah Whitacre, Greg Whitsitt, and others.</p>
</div>


  </section>
  <footer>
    <p class="meta">
      


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    
    <ul class="pager">
      
      <li class="previous"><a class="basic-alignment left"
        href="/2013/02/evangelizing-user-experience/" title="Previous Post:
        Evangelizing User Experience">&laquo; Previous Post</a></li>
      
      <li><a href="/blog/archives">Blog Archives</a></li>
      
      <li class="next"><a class="basic-alignment right" href="/2013/03/cerner-and-tycho/"
        title="Next Post: Cerner and Tycho">Next Post &raquo;</a></li>
      
    </ul>
  </footer>
</article>

<aside class="sidebar-nav span4">
  
    <section class="well">
  <h2>Recent Posts</h2>
  <ul id="recent_posts" class="nav nav-list">
    
      <li>
        <a href="/blog/cerner-open-sources-its-kafka-utilities/">Cerner Open Sources Its Kafka Utilities</a>
      </li>
    
      <li>
        <a href="/blog/cerner-and-the-sdlc/">Cerner and the SDLC</a>
      </li>
    
      <li>
        <a href="/blog/bad-design-is-bad-for-your-health-why-data-visualization-details-matter/">Bad Design Is Bad for Your Health: Why Data Visualization Details Matter</a>
      </li>
    
      <li>
        <a href="/blog/2-to-the-5th-coding-competition-2017/">2^5 Coding Competition 2017: 32 Lines or Less</a>
      </li>
    
      <li>
        <a href="/blog/announcing-bunsen-fhir-data-with-apache-spark/">Announcing Bunsen: FHIR Data With Apache Spark</a>
      </li>
    
  </ul>
</section>
<section class="divider">
  <svg width="70" height="10">
   <rect width="10" height="10" x="0" y="0" style="fill:rgb(20,124,193)" />
   <rect width="10" height="10" x="20" y="0" style="fill:rgb(121,193,68)" />
   <rect width="10" height="10" x="40" y="0" style="fill:rgb(20,124,193)" />
   <rect width="10" height="10" x="60" y="0" style="fill:rgb(121,193,68)" />
</svg>
</section>
<section class="well">
  <h2>GitHub Repos</h2>
  <ul id="gh_repos" class="nav">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/cerner">@cerner</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'cerner',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


  
</aside>


    </div>
  </div>
  
<script id="search-results-template" type="text/mustache">
  {{#entries}}
    <article class="search-result">
        <div class="search-meta meta">
        {{#date}}<time datetime="{{pubdate}}" pubdate>{{displaydate}}</time>{{/date}} | {{author}}
        </div>
        <a href="{{url}}">{{title}}</a>
    </article>
  {{/entries}}
</script>

<script type="text/javascript">
  $(function() {
    $('#search-query').lunrSearch({
      indexUrl: '/javascripts/index.json',   // Url for the .json file containing search index data
      results : '#search-results',  // selector for containing search results element
      entries : '.entries',         // selector for search entries containing element (contained within results above)
      template: '#search-results-template'  // selector for Mustache.js template
    });
    //Currently ignoring the "return/enter" keystroke when searching (as this would just result in a 404 for the page lookup).
    $('#search-query').keydown(function(event){
      if(event.keyCode == 13) {
        event.preventDefault();
        return false;
      }
    });
  });
</script>

  <footer role="contentinfo" class="page-footer">
  <div class="container-fluid">
    <div class="row">
      <div class="span2">
          <img src="/images/Cerner_White_Horizontal.png" alt="Cerner Logo" />
      </div>
      <div class="span10 pull-left">
          <p>&copy; 2018</p>
      </div>
    </div>
  </div>
</footer>


  










</body>
</html>
